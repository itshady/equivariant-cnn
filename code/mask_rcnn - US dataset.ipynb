{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "d0a5e771",
      "metadata": {},
      "source": [
       "# Mask R-CNN for Ultrasound Microrobot Detection\n",
       "\n",
       "This notebook demonstrates how to use a custom dataset with Mask R-CNN to detect microrobots from ultrasound images. \n",
       "\n",
       "The dataset is assumed to have the following structure:\n",
       "\n",
       "```\n",
       "root_dir/\n",
       "    images/\n",
       "         train/   # contains .png images\n",
       "         test/    # contains .png images\n",
       "    labels/\n",
       "         train/   # contains .txt files with bounding box labels\n",
       "         test/    # contains .txt files with bounding box labels\n",
       "```\n",
       "\n",
       "Each label file is a text file with a single line like:\n",
       "\n",
       "```\n",
       "0 0.569076 0.381246 0.115152 0.130603\n",
       "```\n",
       "\n",
       "where the first value is a placeholder, and the next four are normalized `[x_center, y_center, width, height]` values. These are converted to absolute `[xmin, ymin, xmax, ymax]` coordinates during data loading."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "f320f4ce",
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import numpy as np\n",
       "import torch\n",
       "from PIL import Image\n",
       "from torch.utils.data import Dataset, DataLoader\n",
       "import torchvision\n",
       "import torchvision.transforms as T\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "# Check device\n",
       "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
       "print('Using device:', device)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "11f78a9e",
      "metadata": {},
      "source": [
       "## Custom Dataset for Mask R-CNN\n",
       "\n",
       "This dataset class loads an image and its corresponding label file, converts the normalized bounding box `[x_center, y_center, width, height]` to absolute coordinates `[xmin, ymin, xmax, ymax]` and returns a target dictionary as expected by Mask R-CNN."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a18bdfa",
      "metadata": {},
      "outputs": [],
      "source": [
       "class USMicrorobotDetectionDataset(Dataset):\n",
       "    def __init__(self, root_dir, split='train', transforms=None):\n",
       "        \"\"\"\n",
       "        Args:\n",
       "            root_dir (str): Path to the dataset root directory.\n",
       "            split (str): 'train' or 'test'.\n",
       "            transforms: (callable, optional) Transforms to apply to the image.\n",
       "        \"\"\"\n",
       "        self.root_dir = root_dir\n",
       "        self.split = split\n",
       "        self.transforms = transforms\n",
       "        self.images_dir = os.path.join(root_dir, 'images', split)\n",
       "        self.labels_dir = os.path.join(root_dir, 'labels', split)\n",
       "        self.image_files = sorted([f for f in os.listdir(self.images_dir) if f.lower().endswith('.png')])\n",
       "\n",
       "    def __len__(self):\n",
       "        return len(self.image_files)\n",
       "\n",
       "    def __getitem__(self, idx):\n",
       "        # Load image\n",
       "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
       "        image = Image.open(img_path).convert('RGB')  # convert grayscale to RGB\n",
       "        width, height = image.size\n",
       "\n",
       "        # Load corresponding label file\n",
       "        label_file = os.path.splitext(self.image_files[idx])[0] + '.txt'\n",
       "        label_path = os.path.join(self.labels_dir, label_file)\n",
       "        with open(label_path, 'r') as f:\n",
       "            line = f.readline().strip()\n",
       "            # Drop the first value, keeping only the 4 bounding box values\n",
       "            values = [float(x) for x in line.split()[1:]]  # [x_center, y_center, w, h]\n",
       "\n",
       "        # Convert normalized bbox to absolute coordinates\n",
       "        x_center, y_center, w_norm, h_norm = values\n",
       "        x_center_abs = x_center * width\n",
       "        y_center_abs = y_center * height\n",
       "        w_abs = w_norm * width\n",
       "        h_abs = h_norm * height\n",
       "        xmin = x_center_abs - w_abs / 2\n",
       "        ymin = y_center_abs - h_abs / 2\n",
       "        xmax = x_center_abs + w_abs / 2\n",
       "        ymax = y_center_abs + h_abs / 2\n",
       "\n",
       "        box = [xmin, ymin, xmax, ymax]\n",
       "\n",
       "        # Create target dictionary\n",
       "        target = {}\n",
       "        target['boxes'] = torch.as_tensor([box], dtype=torch.float32)\n",
       "        target['labels'] = torch.ones((1,), dtype=torch.int64)  # assuming one class: microrobot\n",
       "        target['image_id'] = torch.tensor([idx])\n",
       "        area = (xmax - xmin) * (ymax - ymin)\n",
       "        target['area'] = torch.tensor([area], dtype=torch.float32)\n",
       "        target['iscrowd'] = torch.zeros((1,), dtype=torch.int64)\n",
       "\n",
       "        if self.transforms is not None:\n",
       "            image = self.transforms(image)\n",
       "\n",
       "        return image, target\n",
       "\n",
       "# Example: Check the number of samples\n",
       "root_dir = 'UsMicroMagSet-main/flagella'  # update with your dataset path\n",
       "dataset = USMicrorobotDetectionDataset(root_dir, split='train', transforms=T.Compose([T.ToTensor()]))\n",
       "print('Number of training samples:', len(dataset))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f6e49e47",
      "metadata": {},
      "source": [
       "## Data Loaders\n",
       "\n",
       "We use a custom collate function for detection tasks."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "37470c68",
      "metadata": {},
      "outputs": [],
      "source": [
       "def collate_fn(batch):\n",
       "    return tuple(zip(*batch))\n",
       "\n",
       "train_dataset = USMicrorobotDetectionDataset(root_dir, split='train', transforms=T.Compose([T.ToTensor()]))\n",
       "test_dataset = USMicrorobotDetectionDataset(root_dir, split='test', transforms=T.Compose([T.ToTensor()]))\n",
       "\n",
       "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
       "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
       "\n",
       "print('Train samples:', len(train_dataset), '| Test samples:', len(test_dataset))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c8a3e2a5",
      "metadata": {},
      "source": [
       "## Model Setup: Mask R-CNN\n",
       "\n",
       "We load a pre-trained Mask R-CNN and modify it for our one-class (microrobot) detection.\n",
       "\n",
       "For detection tasks, we usually have one extra class for background. Hence, set `num_classes = 2`."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60e5811",
      "metadata": {},
      "outputs": [],
      "source": [
       "import torchvision\n",
       "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
       "\n",
       "# Load a pre-trained Mask R-CNN model\n",
       "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
       "\n",
       "# Number of classes: background and microrobot\n",
       "num_classes = 2\n",
       "\n",
       "# Replace the box predictor\n",
       "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
       "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
       "\n",
       "model.to(device)\n",
       "print('Model loaded on:', device)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c289e1aa",
      "metadata": {},
      "source": [
       "## Training Loop\n",
       "\n",
       "This is a basic training loop for Mask R-CNN. Note that training detection models can be resource intensive, so adjust the number of epochs and batch sizes as needed."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5e8825",
      "metadata": {},
      "outputs": [],
      "source": [
       "import torch.optim as optim\n",
       "\n",
       "# Define the optimizer\n",
       "params = [p for p in model.parameters() if p.requires_grad]\n",
       "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
       "\n",
       "num_epochs = 10\n",
       "\n",
       "for epoch in range(num_epochs):\n",
       "    model.train()\n",
       "    epoch_loss = 0\n",
       "    for imgs, targets in train_loader:\n",
       "        imgs = list(img.to(device) for img in imgs)\n",
       "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
       "        \n",
       "        loss_dict = model(imgs, targets)\n",
       "        losses = sum(loss for loss in loss_dict.values())\n",
       "        loss_value = losses.item()\n",
       "        epoch_loss += loss_value\n",
       "        \n",
       "        optimizer.zero_grad()\n",
       "        losses.backward()\n",
       "        optimizer.step()\n",
       "    \n",
       "    print(f\"Epoch {epoch} Loss: {epoch_loss/len(train_loader):.4f}\")\n",
       "\n",
       "    # Optionally, evaluate on the test set every epoch\n",
       "    model.eval()\n",
       "    total_loss = 0\n",
       "    total_samples = 0\n",
       "    with torch.no_grad():\n",
       "        for imgs, targets in test_loader:\n",
       "            imgs = list(img.to(device) for img in imgs)\n",
       "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
       "            loss_dict = model(imgs, targets)\n",
       "            losses = sum(loss for loss in loss_dict.values())\n",
       "            total_loss += losses.item() * len(imgs)\n",
       "            total_samples += len(imgs)\n",
       "    print(f\"Epoch {epoch} | Test Loss: {total_loss/total_samples:.4f}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e3454d3e",
      "metadata": {},
      "source": [
       "## Save the Model\n",
       "\n",
       "After training, you can save your model for future inference."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e447bd7",
      "metadata": {},
      "outputs": [],
      "source": [
       "torch.save(model.state_dict(), 'mask_rcnn_microrobot.pth')\n",
       "print('Model saved!')"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.x"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }   